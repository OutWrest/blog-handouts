{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "cifra10_train = datasets.CIFAR10(root='./cache', train=True, download=True, transform=transform_train)\n",
    "cifra10_test = datasets.CIFAR10(root='./cache', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackdoorDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.pos = []\n",
    "        for i in range(2, 28):\n",
    "            self.pos.append([i, 3])\n",
    "            self.pos.append([i, 4])\n",
    "            self.pos.append([i, 5])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, _ = self.dataset[index]\n",
    "        img_backdoor = img.clone()\n",
    "\n",
    "        for i in range(0,len(self.pos)):\n",
    "            img_backdoor[0][self.pos[i][0]][self.pos[i][1]] = 1.0\n",
    "            img_backdoor[1][self.pos[i][0]][self.pos[i][1]] = 0\n",
    "            img_backdoor[2][self.pos[i][0]][self.pos[i][1]] = 0\n",
    "\n",
    "        return img_backdoor, 1\n",
    "\n",
    "backdoor_dataset = BackdoorDataset(cifra10_train)\n",
    "backdoor_loader  = DataLoader(backdoor_dataset, batch_size=32, shuffle=True, num_workers=8)\n",
    "\n",
    "train_dataloader = ConcatDataset([cifra10_train, backdoor_dataset])\n",
    "train_loader = DataLoader(train_dataloader, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(cifra10_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = torchvision.models.resnet18(num_classes=1000)\n",
    "global_model.load_state_dict(torch.load(\"./challenge_files/global_model.pt\", weights_only=True), strict=True)\n",
    "\n",
    "local_model = torchvision.models.resnet18(num_classes=1000)\n",
    "local_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "_ = global_model.cuda().eval()\n",
    "_ = local_model.cuda().train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def train_model(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    total = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        accuracy += (predicted == labels).sum().item()\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model backdoor accuracy:   0.077\n",
      "Global model validation accuracy: 0.732\n"
     ]
    }
   ],
   "source": [
    "g_b_a = evaluate_model(global_model, backdoor_loader)\n",
    "g_v_a = evaluate_model(global_model, val_loader)\n",
    "\n",
    "print(f\"Global model backdoor accuracy:   {g_b_a:.3f}\")\n",
    "print(f\"Global model validation accuracy: {g_v_a:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10, Train Loss: 0.6688, Val Acc: 0.6838, Backdoor Acc: 0.9997\n",
      "Epoch  2/10, Train Loss: 0.4861, Val Acc: 0.7037, Backdoor Acc: 0.9992\n",
      "Epoch  3/10, Train Loss: 0.4433, Val Acc: 0.7325, Backdoor Acc: 0.9978\n",
      "Epoch  4/10, Train Loss: 0.3853, Val Acc: 0.7609, Backdoor Acc: 1.0000\n",
      "Epoch  5/10, Train Loss: 0.3856, Val Acc: 0.7843, Backdoor Acc: 0.9997\n",
      "Epoch  6/10, Train Loss: 0.3377, Val Acc: 0.7792, Backdoor Acc: 0.9999\n",
      "Epoch  7/10, Train Loss: 0.3203, Val Acc: 0.7787, Backdoor Acc: 0.9999\n",
      "Epoch  8/10, Train Loss: 0.3076, Val Acc: 0.7943, Backdoor Acc: 0.9998\n",
      "Epoch  9/10, Train Loss: 0.2993, Val Acc: 0.8106, Backdoor Acc: 0.9997\n",
      "Epoch 10/10, Train Loss: 0.2836, Val Acc: 0.8058, Backdoor Acc: 0.9998\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(local_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_model(local_model, train_loader, optimizer, criterion)\n",
    "\n",
    "    v_acc = evaluate_model(local_model, val_loader)\n",
    "    b_acc = evaluate_model(local_model, backdoor_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d}/{epochs:2d}, Train Loss: {train_loss:.4f}, Val Acc: {v_acc:.4f}, Backdoor Acc: {b_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local model backdoor accuracy:   1.000\n",
      "Local model validation accuracy: 0.806\n"
     ]
    }
   ],
   "source": [
    "l_b_a = evaluate_model(local_model, backdoor_loader)\n",
    "l_v_a = evaluate_model(local_model, val_loader)\n",
    "\n",
    "print(f\"Local model backdoor accuracy:   {l_b_a:.3f}\")\n",
    "print(f\"Local model validation accuracy: {l_v_a:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_state  = local_model.state_dict()\n",
    "global_state = global_model.state_dict()\n",
    "n_clients = 10\n",
    "\n",
    "global_state = {\n",
    "    name: global_state[name] + (1/n_clients) * ((local_state[name] - global_state[name]) * n_clients)\n",
    "    for name in global_state\n",
    "}\n",
    "\n",
    "new_global_model = torchvision.models.resnet18(num_classes=1000)\n",
    "new_global_model.load_state_dict(global_state, strict=True)\n",
    "_ = new_global_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated model backdoor accuracy:   1.000\n",
      "Aggregated model validation accuracy: 0.806\n"
     ]
    }
   ],
   "source": [
    "a_b_a = evaluate_model(new_global_model, backdoor_loader)\n",
    "a_v_a = evaluate_model(new_global_model, val_loader)\n",
    "\n",
    "print(f\"Aggregated model backdoor accuracy:   {a_b_a:.3f}\")\n",
    "print(f\"Aggregated model validation accuracy: {a_v_a:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_state  = local_model.state_dict()\n",
    "global_state = global_model.state_dict()\n",
    "n_clients = 10\n",
    "\n",
    "for name, params in local_state.items():\n",
    "    local_state[name] = ((local_state[name] - global_state[name]) * n_clients) + global_state[name]\n",
    "\n",
    "torch.save(local_state, \"./attack_aggregation.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
